---
title: 并行计算基础知识
subtitle: 
layout: post
author: "熊巍"
header-style: text
tags:
  - MPI
  - 并行计算
---

计算机界有一个著名的定律叫摩尔定律，是由Intel创始人之一戈登摩尔所提出的。他说，集成电路上可容纳的元器件的数目，约每隔18-24个月便会增加一倍，性能也将提升一倍。然而，晶体管的数量增加，功耗和产生的热量也随之大幅增加。当散热能力近乎达到极限时，通过增加单个CPU的性能来换取更高的运算性能已不可取。考虑到物理极限的约束和设计更复杂的架构所产生的高额成本等因素，开始朝向多核的方向发展。

# 如何实现并行计算？

将一个计算任务分配到多个节点上去计算，通常有两种方式。一个是任务并行，一个数据并行。顾名思义，任务并行就是每个节点执行不同的任务，而数据并行就是每个节点存储不同的数据。因为本系列教程的重点是MPI，因此从程序这一划分粒度来分类，可分为SPMD（单程序多数据）并行和MPMD（多程序多数据并行）。

SPMD即为多个计算集群都运行同一个程序，然而他们各自的存储是独立的。比如进程0和进程1分别有一个数组A，这两个数组可以分别为[0,2,3]和[1,2,3]。当执行一个程序，要求计算A=A+1时，进程0和进程1会同时用各自的数组A去执行相同的程序，得到的结果分别为[1,3,4]和[2,3,4]。所以，在这种情况下，如果想对某一进程执行特殊于其他进程的操作，可以加一个if(process_id==0)的语句，从而让进程1不进入该if语句中去。MPMD则相当于各自进程执行各自的程序。SPMD和MPMD的表达能力是相同的，只是针对不同的问题编写难易而已。MPI是可以写SPMD和MPMD的并行程序的。之所以这么设计，是由并行计算机的体系结构所决定的，因此有必要简单描述一下计算机的运作方式。

当前的计算机采用冯诺依曼体系结构，CPU执行的指令和参与计算所用到的数据都存储于内存（该内存指的是存储设备，不单指内存条）当中，而CPU会按照程序顺序执行。众所周知，内存是线性存储的。即假一个内存有256个存储空间，则这256个存储空间的地址会依次对应于0-255。因此，将CPU设计成多个核心时，需要解决存储问题。

在设计并行计算机时，最直接的方式就是多个计算单元共享一个内存，即如下图所示。共享内存的编程在数据交换和访问上有较大的优势，程序编写起来更加简单。但在扩展性上有较大的瓶颈。另一种方式为，分布式内存。即每个计算单元有单独的内存，计算单元之间的数据访问通过互联网络去传输。这一架构在可移植性和扩展上会强很多，但消息的传递会成为程序设计中的难点。将这两点结合，即是分布式共享内存并行计算机的架构，也是当今最常用的体系结构。之后的MPI编程中，将会涉及很多消息通信，之后的学习会加深对此的理解。